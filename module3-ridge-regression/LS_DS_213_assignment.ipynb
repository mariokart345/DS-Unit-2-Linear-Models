{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "LS_DS_213_assignment.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mariokart345/DS-Unit-2-Linear-Models/blob/master/module3-ridge-regression/LS_DS_213_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVBAt5ACCboq"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 1, Module 3*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IXUfiQ2UKj6"
      },
      "source": [
        "# Ridge Regression\n",
        "\n",
        "## Assignment\n",
        "\n",
        "We're going back to our other **New York City** real estate dataset. Instead of predicting apartment rents, you'll predict property sales prices.\n",
        "\n",
        "But not just for condos in Tribeca...\n",
        "\n",
        "- [ ] Use a subset of the data where `BUILDING_CLASS_CATEGORY` == `'01 ONE FAMILY DWELLINGS'` and the sale price was more than 100 thousand and less than 2 million.\n",
        "- [ ] Do train/test split. Use data from January â€”Â March 2019 to train. Use data from April 2019 to test.\n",
        "- [ ] Do one-hot encoding of categorical features.\n",
        "- [ ] Do feature selection with `SelectKBest`.\n",
        "- [ ] Fit a ridge regression model with multiple features. Use the `normalize=True` parameter (or do [feature scaling](https://scikit-learn.org/stable/modules/preprocessing.html) beforehand â€”Â use the scaler's `fit_transform` method with the train set, and the scaler's `transform` method with the test set)\n",
        "- [ ] Get mean absolute error for the test set.\n",
        "- [ ] As always, commit your notebook to your fork of the GitHub repo.\n",
        "\n",
        "The [NYC Department of Finance](https://www1.nyc.gov/site/finance/taxes/property-rolling-sales-data.page) has a glossary of property sales terms and NYC Building Class Code Descriptions. The data comes from the [NYC OpenData](https://data.cityofnewyork.us/browse?q=NYC%20calendar%20sales) portal.\n",
        "\n",
        "\n",
        "## Stretch Goals\n",
        "\n",
        "Don't worry, you aren't expected to do all these stretch goals! These are just ideas to consider and choose from.\n",
        "\n",
        "- [ ] Add your own stretch goal(s) !\n",
        "- [ ] Instead of `Ridge`, try `LinearRegression`. Depending on how many features you select, your errors will probably blow up! ðŸ’¥\n",
        "- [ ] Instead of `Ridge`, try [`RidgeCV`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html).\n",
        "- [ ] Learn more about feature selection:\n",
        "    - [\"Permutation importance\"](https://www.kaggle.com/dansbecker/permutation-importance)\n",
        "    - [scikit-learn's User Guide for Feature Selection](https://scikit-learn.org/stable/modules/feature_selection.html)\n",
        "    - [mlxtend](http://rasbt.github.io/mlxtend/) library\n",
        "    - scikit-learn-contrib libraries: [boruta_py](https://github.com/scikit-learn-contrib/boruta_py) & [stability-selection](https://github.com/scikit-learn-contrib/stability-selection)\n",
        "    - [_Feature Engineering and Selection_](http://www.feat.engineering/) by Kuhn & Johnson.\n",
        "- [ ] Try [statsmodels](https://www.statsmodels.org/stable/index.html) if youâ€™re interested in more inferential statistical approach to linear regression and feature selection, looking at p values and 95% confidence intervals for the coefficients.\n",
        "- [ ] Read [_An Introduction to Statistical Learning_](http://faculty.marshall.usc.edu/gareth-james/ISL/ISLR%20Seventh%20Printing.pdf), Chapters 1-3, for more math & theory, but in an accessible, readable way.\n",
        "- [ ] Try [scikit-learn pipelines](https://scikit-learn.org/stable/modules/compose.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9eSnDYhUGD7"
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Applied-Modeling/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'\n",
        "    \n",
        "# Ignore this Numpy warning when using Plotly Express:\n",
        "# FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore', category=FutureWarning, module='numpy')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJBD4ruICm1m"
      },
      "source": [
        "import pandas as pd\n",
        "import pandas_profiling\n",
        "\n",
        "# Read New York City property sales data\n",
        "df = pd.read_csv(DATA_PATH+'condos/NYC_Citywide_Rolling_Calendar_Sales.csv')\n",
        "\n",
        "# Change column names: replace spaces with underscores\n",
        "df.columns = [col.replace(' ', '_') for col in df]\n",
        "\n",
        "# SALE_PRICE was read as strings.\n",
        "# Remove symbols, convert to integer\n",
        "df['SALE_PRICE'] = (\n",
        "    df['SALE_PRICE']\n",
        "    .str.replace('$','')\n",
        "    .str.replace('-','')\n",
        "    .str.replace(',','')\n",
        "    .astype(int)\n",
        ")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukkKSsDQCbox"
      },
      "source": [
        "# BOROUGH is a numeric column, but arguably should be a categorical feature,\n",
        "# so convert it from a number to a string\n",
        "df['BOROUGH'] = df['BOROUGH'].astype(str)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEOX_1y7Cbox"
      },
      "source": [
        "# Reduce cardinality for NEIGHBORHOOD feature\n",
        "\n",
        "# Get a list of the top 10 neighborhoods\n",
        "top10 = df['NEIGHBORHOOD'].value_counts()[:10].index\n",
        "\n",
        "# At locations where the neighborhood is NOT in the top 10, \n",
        "# replace the neighborhood with 'OTHER'\n",
        "df.loc[~df['NEIGHBORHOOD'].isin(top10), 'NEIGHBORHOOD'] = 'OTHER'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inv-p8Ym6Hk7"
      },
      "source": [
        "#Removing Outliers and restricting dataset for One Family Dwellings\r\n",
        "df = df[df['BUILDING_CLASS_CATEGORY']=='01 ONE FAMILY DWELLINGS']\r\n",
        "df.drop(columns='BUILDING_CLASS_CATEGORY',inplace=True)\r\n",
        "df = df[(df['SALE_PRICE'] > 100000)&(df['SALE_PRICE'] < 2000000)]\r\n",
        "#Coverting Column to datetime to then seperate January-March for training data whilst April as testing\r\n",
        "df['SALE_DATE'] = pd.to_datetime(df['SALE_DATE'], infer_datetime_format=True)\r\n",
        "train = df[df['SALE_DATE'] < '2019-03-31']\r\n",
        "test = df[df['SALE_DATE'] >= '2019-03-31']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aG9jqXd3BslE"
      },
      "source": [
        "#Making feature and target vector dataframes(Removal Of 'SALE_DATE','EASE-MENT' are because of the incompatable datatypes for SelectKBest)\r\n",
        "x_train,x_test = train.drop(columns=['SALE_PRICE', 'SALE_DATE','EASE-MENT','ADDRESS']),test.drop(columns=['SALE_PRICE','SALE_DATE','EASE-MENT','ADDRESS'])\r\n",
        "y_train,y_test = train['SALE_PRICE'],test['SALE_PRICE']"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmsvdhJdBgqB"
      },
      "source": [
        "#Importing and Instantiate transformers\r\n",
        "from category_encoders import OneHotEncoder\r\n",
        "from sklearn.feature_selection import SelectKBest\r\n",
        "encode = OneHotEncoder(use_cat_names=True)\r\n",
        "SKBest = SelectKBest(k=35)\r\n",
        "#Fiting training data and transforming test data(OneHotEncoder)\r\n",
        "XT_train = encode.fit_transform(x_train)\r\n",
        "XT_test = encode.transform(x_test)\r\n",
        "#Fiting training data and transforming test data(SelectKBest)\r\n",
        "XTT_train = SKBest.fit_transform(XT_train,y_train)\r\n",
        "XTT_test = SKBest.transform(XT_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvnHvdmlI3bs",
        "outputId": "e301c395-cfac-46f3-e401-031d05bd58bb"
      },
      "source": [
        "#BaseLine Before going into Regression\r\n",
        "from sklearn.metrics import mean_absolute_error\r\n",
        "y_pred = [y_train.mean()] * len(y_train)\r\n",
        "Baseline_mae = mean_absolute_error(y_train,y_pred)\r\n",
        "print(f'Baseline MAE:{Baseline_mae}')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline MAE:214721.52773001452\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9OW1xOYCJlC",
        "outputId": "08655232-c929-4661-8a04-fa4368055cf5"
      },
      "source": [
        "#Instatinating Models\r\n",
        "from sklearn.linear_model import LinearRegression, RidgeCV\r\n",
        "LRModel = LinearRegression()\r\n",
        "RModel = RidgeCV(normalize=True)\r\n",
        "#Fitting Models\r\n",
        "LRModel.fit(XTT_train,y_train)\r\n",
        "RModel.fit(XT_train,y_train)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RidgeCV(alphas=array([ 0.1,  1. , 10. ]), cv=None, fit_intercept=True,\n",
              "        gcv_mode=None, normalize=True, scoring=None, store_cv_values=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U16-6DWYVaYn",
        "outputId": "45e573f3-5e7c-44cb-b1bc-82fb8998637a"
      },
      "source": [
        "#Getting Mean Absolute Error for Linear Regression Model and Ridge Regression Model\r\n",
        "from sklearn.metrics import mean_absolute_error\r\n",
        "print(f'LRModel Train MAE:{mean_absolute_error(y_train,LRModel.predict(XTT_train))}\\nLRModel Test MAE:{mean_absolute_error(y_test,LRModel.predict(XTT_test))}')\r\n",
        "print(f'\\nRModel Train MAE:{mean_absolute_error(y_train,RModel.predict(XT_train))}\\nRModel Test MAE:{mean_absolute_error(y_test,RModel.predict(XT_test))}')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LRModel Train MAE:208578.76156986976\n",
            "LRModel Test MAE:211655.60416792295\n",
            "\n",
            "RModel Train MAE:104251.1952430973\n",
            "RModel Test MAE:163527.48816308865\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}